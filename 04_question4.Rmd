---
title: "04_question4"
author: '44'
date: "2022-06-02"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Q4 

You have received data on patients with cardiac monitoring devices that detect atrial fibrillation events.
In reporting the counts of atrial fibrillation events within one month, 
for some patients (Group A) the number of events is available while for the rest (Group B) 
you only have a binary indicator of whether the count was non-zero. 

There is no information in the data set that will let you know whether 
the value presented is a count or a binary indicator (i.e., data from groups A and B are mixed together). 

The data is available in ATFIB.txt and contains the following columns:
- id: unique patient identifier
- outcome: observed outcome (i.e., the direct actual count of atrial fibrillation events or 
the binary indicator of a non-zero count)


## (a) 

Given what you know about the data collection, you realize that you could consider the data to arise from a Poisson random variable $Y$ with mean $\lambda$ for which you observe either $Y$ directly (Group A), or the $I(Y > 0)$ (Group B). 

Which group each individual belongs to can be considered missing data. 

Define a latent variable $Z \sim Bernoulli(p)$, independent of $Y$, 
as a binary indicator of whether $Y$ is observed directly 
(i.e., $Z = 1$ indicates an observation is from Group A and $Z = 0$ indicates an observation is from Group B). 

The observed outcome $X$ can then be defined in terms of $Y \sim Poisson(\lambda)$, $I(Y > 0)$ and $Z$.

Write out the likelihood for:

### i. The observed data (X). 

Hint: Consider the cases 
- (i) X = 0: there is no event
- (ii) X = 1: there is $= 1$ or $> 1$ events
- (iii) X = k, k > 1: there are k events


$$
\begin{split}
& Y_i|Z_i=1 \sim Poisson(\lambda)\\
& P(Y = 0) = e^{-\lambda}\\
& P(Y = 0 | Z = 1) = e^{-\lambda} \\
& P(Y = 1 | Z = 1) = \lambda e^{-\lambda}\\  
& Y_i|Z_i=0 \sim Bernoulli(1 - e^{-\lambda})\\
& P(Y = 0 | Z = 0) = e^{-\lambda}\\
& P(Y = 1 | Z = 0) = 1 - e^{-\lambda}\\
& Z_i \sim Bernoulli(p_3)
\end{split}
$$

The mixture of degenerate distribution at zero with probability $p_1$ and Poisson distribution with probability $1 - p_1$; so the Poisson mixed with two point masses at 0 with $p_1$ and at $1$ with $p_2$; $p_3 = 1- p_1 - p_2$.

$$
\begin{split}
P(Y = y) & = P(Y|Z=0) \times P(Z=0) + P(Y |Z=1) \times P(Z = 1)\\
& = \begin{cases}
p_1 + p_3 e^{-\lambda} = e^{-\lambda} & y = 0 \\
p_2 + p_3 \lambda e^{-\lambda}  & y = 1\\
0 + p_3 \frac {\lambda^ye^{-\lambda}} {y!} & y > 1
\end{cases}\\
p_1 & = P(Y = 0|Z=0) \times P(Z=0) = 
\frac {\lambda^{0} e^{-\lambda}} {0!} p_3 = e^{-\lambda} (1 - p_3)\\
p_2 & = P(Y = 1|Z=0) \times P(Z=0) = (1 - e^{-\lambda}) (1 - p_3) \\
 p_1 & + p_2 + p_3 = 1 \\
L(p_3, \lambda | Y ) & = \prod_{i \in \{y_i = 0\}} e^{-\lambda}
\prod_{i \in \{y_i = 1\}} (1 - e^{-\lambda}) (1 - p_3) + p_3 \lambda e^{-\lambda}
\prod_{i \in \{y_i > 1\}} p_3 \frac {\lambda^ye^{-\lambda}} {y!}
\end{split}
$$

### ii. The complete data $(Y, Z)$. 
Hint: Consider the cases for when 
(i) Z = 1,Y = k, 
(ii) Z = 0, Y = 0, 
(iii) Z = 0, Y = k, k>0

$$
\begin{split}
P(Y, Z) & = P(Y|Z) \times P(Z) = 
\begin{cases}
P(Y = 0 |Z = 1) \times P(Z = 1) = e^{-\lambda} p_3\\
P(Y = 1 |Z = 1) \times P(Z = 1) = \lambda e^{-\lambda} p_3\\
P(Y = k |Z = 1) \times P(Z = 1) = \frac {\lambda^ k  e^{-\lambda}} {k} p_3\\
P(Y = 0 |Z = 0) \times P(Z = 0) = e^{-\lambda}(1-p_3)\\
P(Y = k |Z = 0) \times P(Z = 0) = 0\\
P(Y = 1 |Z = 0) \times P(Z = 0) = (1 - e^{-\lambda})(1-p_3)
\end{cases}\\
L(p_3, \lambda | (Y, Z) ) & = \prod_{i \in \{z_i = 1\}} \frac {\lambda^y_i  e^{-\lambda}} {y_i} p_3
\prod_{i \in \{z_i = 0, y_i = 0\}} e^{-\lambda}(1-p_3)
\prod_{i \in \{z_i = 0, y_i = 1\}} (1 - e^{-\lambda})(1-p_3)\\
 & = \prod_{i \in \{z_i = 1\}} \frac {\lambda^y_i  e^{-\lambda}} {y_i} p_3
\prod_{i \in \{z_i = 0, y_i = 0\}} p_1
\prod_{i \in \{z_i = 0, y_i = 1\}} p_2
\end{split}
$$

When $Z = 0$, we do not have the information of exact $Y$, but a Bernoulli conditional on the probability of $Z = 0$. 


## (b) Numerically optimize the observed data log-likelihood using "optim" in R, 
to obtain the estimates, standard errors, and 95% confidence intervals for $\lambda$ and $p$.

Provide non-technical interpretations for these parameters. 
Comment on how you think these results would differ if you had data on $Z$, 
and the reason for those differences.

$$
\begin{split}
L(p_3, \lambda | Y ) & = \prod_{i \in \{y_i = 0\}} e^{-\lambda}
\prod_{i \in \{y_i = 1\}} (1 - e^{-\lambda}) (1 - p_3) + p_3 \lambda e^{-\lambda}
\prod_{i \in \{y_i > 1\}} p_3 \frac {\lambda^ye^{-\lambda}} {y!}\\
logL(p_3, \lambda | Y ) & = -\sum_{i \in \{y_i = 0\}} {\lambda} + 
\sum_{i \in \{y_i = 1\}} log\Big((1 - e^{-\lambda}) (1 - p_3) + p_3 \lambda e^{-\lambda}\Big) + 
\sum_{i \in \{y_i > 1\}} log (p_3) + y log (\lambda) - \lambda - log({y!})
\end{split}
$$


```{r fig.height=3, fig.width=3}
library(readr)
library(tidyverse)

data_4 <- read_table("data/ATFIB.txt") %>% 
  janitor::clean_names()

#' Title Loglikelihood for inflated mixture model with imcomplete dataset
#' @param lambda `numeric` a positive value as Poisson distribution parameter
#' @param p `numeric` a positive value in [0, 1] as Bernoulli distribution parameter
#' @param datay `data.frame` the observed dataset 
#' @return `neg_logL` the negative log-likelihood
#' @export
get_logL_inc <- function(parameter,
                         datay) {
  ## need to argue why lambda 
  ## and p are separated 
  p <- parameter[1] %>% as.numeric()
  lambda <- parameter[2] %>% as.numeric()
  
  ## subset the dataset by Y
  y0 <- datay %>% filter(outcome == 0)
  n0 <- nrow(y0)
  y1 <- datay %>% filter(outcome == 1)
  n1 <- nrow(y1)
  yk <- datay %>% filter(outcome > 1)
  
  ## loglikelihood for Y==0
  logL0 <- - lambda * n0 
  ## loglikelihood for Y==1
  logL1 <- (log((1 - exp(-lambda)) * (1 - p) + p * lambda * exp(-lambda))) * n1
  ## for loop to calculate Y==k
  logLk <- 0
  for (yi in yk$outcome) {
    logLk <- logLk + log(p) + yi * log(lambda) - lambda - log(gamma(yi + 1))
    }
  (neg_logL <- -(logL0 + logL1 + logLk))
  return(neg_logL)
}

p_hat <- optim(par = c(0.1, 2),
               fn = get_logL_inc,
               lower = c(0, 1),
               upper = c(1, Inf),
               datay = data_4,
               hessian = T)
(par_mean <- p_hat$par)
(par_sd <- solve(p_hat$hessian) %>% diag() %>% sqrt())
par_mean + 1.96 * par_sd
par_mean - 1.96 * par_sd
```



## (c) You begin to suspect that maybe the data was actually collected consistently, and only represents counts that arise from a $Poisson(\lambda)$ distribution. 

Perform an appropriate statistical test to formally test this assumption for your data. State the null and alternative hypotheses for your test, and the asymptotic distribution of the test statistic under the null. Present your conclusions based on this test.

The Poisson model can be regarded as a special nested case of the mixed model in (a); hence we can use likelihood ratio test to test the hypothesis.

$$
\Lambda = -2 log \Bigg[\frac{sup_{\theta \in \Theta_0} L(\theta)} {sup_{\theta \in \Theta} L(\theta)} \Bigg] \sim \chi^2
$$


```{r}
#' Title Negative likelihood for Poisson regression
#' @param lambda `numeric` a positive value as Poisson distribution parameter
#' @param datay `data.frame` the observed dataset 
#' @return `-logLk` the negative log-likelihood
#' @export
get_logL_pois <- function(lambda,
                          datay) {
  logLk <- 0
  for (yi in data_4$outcome) {
    logLk <- logLk + yi * log(lambda) - lambda - log(gamma(yi + 1))
  }
  return(-logLk)
}

lambda_pois <- optim(par = 1, 
               fn = get_logL_pois,
               method = "Brent",
               lower = 0,
               upper = 6,
               datay = data_4)
lambda_pois$par
```

```{r}
logL_mix <- get_logL_inc(c(1.000, 1.868),
                         datay = data_4)


logL_poisson <- get_logL_pois(lambda = 1.612,
                          datay = data_4)

# logL_mix; logL_poisson

2 * abs(logL_mix - logL_poisson) %>% 
  pchisq(df = 1, lower.tail = FALSE)
```


## (d) Design and conduct a simulation study that evaluates the efficiency of estimation using the incomplete data versus the complete data (i.e., the incomplete data augmented with a column for $Z$). Specifically, report bias and efficiency for estimating $\lambda$. Fix $\lambda = 1$. Vary sample size $(N = 100, 1000)$ and $p \ (p = 0.2,0.5,0.8)$ to generate data from 6 settings. Simulate a reasonable number of replicates.


### i. Submit commented code that describes (i) data generation process, (ii) estimation, and (iii) computation of metrics.

```{r eval=FALSE, include=TRUE}
lambda <- 1
p <- 0.8
N <- 100

#' Title Simulate data for mixture model
#'
#' @param lambda `numeric` parameter for Poisson as Y|Z==1 distribution
#' @param p `numeric` parameter for Bernoulli as Z's distribution
#' @param N `integer` for sample size
#' @param seed `integer` set seed
#' @return `data_sim` a simulated dataset
#' @export

get_sim <- function(lambda = 1,
                    p = 0.5,
                    N = 100,
                    seed) {
  set.seed(seed)
  ## number of Z == 1
  Z1 <- rbinom(1, N, p)
  ## number of Z == 0
  Z0 <- N - Z1
  ## Vector = Z
  Z <- c(rep(1, Z1), rep(0, Z0))
  ##     Y|Z==1 Poisson(\lambda)
  Y <- c(rpois(Z1, lambda), 
         ## Y|Z==0 Bernoulli(1 - \exp(-\lambda))
         unlist(map(rep(1, Z0), 
                    ~rbinom(1, ., (1 - exp(-lambda))))))
  data_sim <- data.frame(Z = Z, Y = Y)
  return(data_sim)
}
sim_num <- 1000
sim_N100_p02 <- map(1:sim_num, ~get_sim(seed = ., N = 100, p = 0.2))
sim_N100_p05 <- map(1:sim_num, ~get_sim(seed = ., N = 100, p = 0.5))
sim_N100_p08 <- map(1:sim_num, ~get_sim(seed = ., N = 100, p = 0.8))
sim_N1k_p02 <- map(1:sim_num, ~get_sim(seed = ., N = 1000, p = 0.2))
sim_N1k_p05 <- map(1:sim_num, ~get_sim(seed = ., N = 1000, p = 0.5))
sim_N1k_p08 <- map(1:sim_num, ~get_sim(seed = ., N = 1000, p = 0.8))

save(sim_N100_p02, sim_N100_p05, sim_N100_p08,
     sim_N1k_p02, sim_N1k_p05, sim_N1k_p08,
     file = "bios_qexam_question_4.Rdata")
```


```{r}
load("bios_qexam_question_4.Rdata")
```


```{r}
#' Title Loglikelihood for inflated mixture model with imcomplete dataset
#' @param lambda `numeric` a positive value as Poisson distribution parameter
#' @param p `numeric` a positive value in [0, 1] as Bernoulli distribution parameter
#' @param datay `data.frame` the observed dataset 
#' @return `neg_logL` the negative log-likelihood
#' @export
get_logL_incomplete <- function(parameter,
                         datayz) {
  ## need to argue why lambda 
  ## and p are seperated 
  p <- parameter[1] %>% as.numeric()
  lambda <- parameter[2] %>% as.numeric()
  
  ## subset the dataset by Y
  y0 <- datayz %>% filter(Y == 0)
  n0 <- nrow(y0)
  y1 <- datayz %>% filter(Y == 1)
  n1 <- nrow(y1)
  yk <- datayz %>% filter(Y > 1)
  
  ## loglikelihood for Y==0
  logL0 <- -lambda * n0 
  ## loglikelihood for Y==1
  logL1 <- (log((1 - exp(-lambda)) * (1 - p) + p * lambda * exp(-lambda))) * n1
  ## for loop to calculate Y==k
  logLk <- 0
  for (yi in yk$Y) {
    logLk <- logLk + log(p) + yi * log(lambda) - lambda - log(gamma(yi + 1))
  }
  (neg_logL <- -(logL0 + logL1 + logLk))
  return(neg_logL)
}

# get_logL_incomplete(c(0.5, 2), sim_N100_p02[[5]])
```


$$
\begin{split}
L(p_3, \lambda | (Y, Z) ) & = \prod_{i \in \{z_i = 1\}} \frac {\lambda^y_i  e^{-\lambda}} {y_i} p_3
\prod_{i \in \{z_i = 0, y_i = 0\}} e^{-\lambda}(1-p_3)
\prod_{i \in \{z_i = 0, y_i = 1\}} (1 - e^{-\lambda})(1-p_3)\\
 & = \prod_{i \in \{z_i = 1\}} \frac {\lambda^y_i  e^{-\lambda}} {y_i} p_3
\prod_{i \in \{z_i = 0, y_i = 0\}} p_1
\prod_{i \in \{z_i = 0, y_i = 1\}} p_2\\
logL(p_3, \lambda | (Y, Z) ) & = \sum_{i \in \{z_i = 1\}} log (p_3) + y_i log (\lambda) - \lambda - log({y_i!})
\sum_{i \in \{z_i = 0, y_i = 0\}} log(p_1)
\sum_{i \in \{z_i = 0, y_i = 1\}} log(p_2)\\
p_1 & = P(Y = 0|Z=0) \times P(Z=0) = 
\frac {\lambda^{0} e^{-\lambda}} {0!} p_3 = e^{-\lambda} (1 - p_3)\\
p_2 & = P(Y = 1|Z=0) \times P(Z=0) = (1 - e^{-\lambda}) (1 - p_3) \\
 p_1 & + p_2 + p_3 = 1 \\
\end{split}
$$

```{r}
get_logL_complete <- function(parameter,
                              datayz) {
  ## need to argue why lambda 
  ## and p are seperated 
  p <- parameter[1] %>% as.numeric()
  lambda <- parameter[2] %>% as.numeric()
  
  p1 <- exp(-lambda) * (1 - p)
  p2 <- (1 - exp(-lambda)) * (1 - p)
  
  ## subset the dataset by Y
  z1 <- datayz %>% filter(Z == 1)
  z0y1 <- datayz %>% filter(Y == 1, Z == 0)
  ny1 <- nrow(z0y1)
  z0y0 <- datayz %>% filter(Y == 0, Z == 0)
  ny0 <- nrow(z0y0)
  
  ## loglikelihood for Y==0 Z==0
  logLy0 <- ny0 * log(p1)
  ## loglikelihood for Y==1 Z==0
  logLy1 <- ny1 * log(p2)
  ## for loop to calculate Y==k
  logLk <- 0
  for (yi in z1$Y) {
    logLk <- logLk + log(p) + yi * log(lambda) - lambda - log(gamma(yi + 1))
  }
  (neg_logL <- -(logLy0 + logLy1 + logLk))
  return(neg_logL)
}
```

```{r eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
get_optim <- function(datayz) {
  par_cpl <- optim(par = c(0.1, 1), 
                   fn = get_logL_complete,
                   lower = c(0, 0),
                   upper = c(1, Inf),
                   datayz = datayz)
  par_icp <- optim(par = c(0.1, 1), 
                   fn = get_logL_incomplete,
                   lower = c(0, 0),
                   upper = c(1, Inf),
                   datayz = datayz)
  result <- c(unlist(par_icp$par), 
              unlist(par_cpl$par)) 
  return(result)
}

result_N100_p02 <- map_dfc(sim_N100_p02, ~try(get_optim(.))) %>% select_if(is.numeric)
result_N100_p05 <- map_dfc(sim_N100_p05, ~try(get_optim(.))) %>% select_if(is.numeric)
result_N100_p08 <- map_dfc(sim_N100_p08, ~try(get_optim(.))) %>% select_if(is.numeric)

result_N1k_p02 <- map_dfc(sim_N1k_p02, ~try(get_optim(.))) %>% select_if(is.numeric)
result_N1k_p05 <- map_dfc(sim_N1k_p05, ~try(get_optim(.))) %>% select_if(is.numeric)
result_N1k_p08 <- map_dfc(sim_N1k_p08, ~try(get_optim(.))) %>% select_if(is.numeric)

save(result_N100_p02, result_N1k_p02,
     result_N100_p05, result_N1k_p05,
     result_N100_p08, result_N1k_p08,
     file = "bios_qexam_quesion_4_result.Rdata")
```


### ii. Summarize your results in a short report (2-3 paragraphs) and 1-2 figures or summary tables. Give hypotheses, conclusions, and recommendations based on what you have found.

```{r}
library(matrixStats)
load("bios_qexam_quesion_4_result.Rdata")

rowMeans(result_N100_p02)
rowMeans(result_N100_p05)
rowMeans(result_N100_p08)
rowMeans(result_N1k_p02)
rowMeans(result_N1k_p05)
rowMeans(result_N1k_p08)

rowMeans(result_N100_p02) - c(0.2, 1, 0.2, 1)
rowMeans(result_N100_p05) - c(0.2, 1, 0.2, 1)
rowMeans(result_N100_p08) - c(0.2, 1, 0.2, 1)
rowMeans(result_N1k_p02) - c(0.2, 1, 0.2, 1)
rowMeans(result_N1k_p05) - c(0.2, 1, 0.2, 1)
rowMeans(result_N1k_p08) - c(0.2, 1, 0.2, 1)

matrixStats::rowSds(as.matrix(result_N100_p02))
matrixStats::rowSds(as.matrix(result_N100_p05))
matrixStats::rowSds(as.matrix(result_N100_p08))
matrixStats::rowSds(as.matrix(result_N1k_p02))
matrixStats::rowSds(as.matrix(result_N1k_p05))
matrixStats::rowSds(as.matrix(result_N1k_p08))
```









